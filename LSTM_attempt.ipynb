{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d5960d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, PredefinedSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from feature_engineering.feature_utils import create_features_from_raw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e704f856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "csv_sequences = \"data/GDPa1_v1.2_sequences.csv\" \n",
    "csv_properties = \"data/GDPa1_v1.2_20250814.csv\"\n",
    "\n",
    "Y = \"HIC\"\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "random_seed = 42\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4e6a36b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_df = pd.read_csv(csv_sequences)\n",
    "prop_df = pd.read_csv(csv_properties)\n",
    "\n",
    "# target dataframe\n",
    "target_df = prop_df[[\"antibody_id\", Y]]\n",
    "\n",
    "# merge target and sequences\n",
    "seq_target = seq_df.merge(target_df, on=\"antibody_id\", how=\"inner\")\n",
    "sequence_features = create_features_from_raw_df(seq_target)\n",
    "# sequence_features has same index as df_raw and its own antibody_id column.\n",
    "# concatenate along columns, drop duplicate antibody_id.\n",
    "df = pd.concat(\n",
    "    [seq_target.reset_index(drop=True),\n",
    "     sequence_features.drop(columns=[\"antibody_id\"]).reset_index(drop=True)],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "13e41caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### amino acid vocab, our way of scaling \n",
    "AMINO_ACIDS = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "aa_to_idx = {aa:i for i, aa in enumerate(AMINO_ACIDS)}\n",
    "\n",
    "# map each amino acid to a 20-dom 0/1 vector\n",
    "def one_hot_encode(seq):\n",
    "    seq = str(seq).strip().upper()\n",
    "    encoded = []\n",
    "    for aa in seq:\n",
    "        vec = [0]*20\n",
    "        if aa in aa_to_idx:\n",
    "            vec[aa_to_idx[aa]] = 1\n",
    "        encoded.append(vec)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fe04cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_cols = [\n",
    "    \"vl_turn\",\n",
    "    \"vh_molecular_weight\",\n",
    "    \"vh_protein_sequence_length\",\n",
    "    \"vh_aromaticity\",\n",
    "    \"vh_helix\",\n",
    "    \"vh_instability\",\n",
    "    \"vh_molar_extinction_oxidized\",\n",
    "    \"vl_aromaticity\",\n",
    "    \"vh_sheet\",\n",
    "    \"G_vl_protein_sequence\",\n",
    "    \"vh_hydrophobic_count\",\n",
    "    \"vh_aromatic_count\",\n",
    "    \"vh_gravy\",\n",
    "    \"Y_vh_protein_sequence\",\n",
    "]\n",
    "\n",
    "df = df.dropna(subset=[Y]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e32301ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AntibodySeqDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols=None):\n",
    "        self.vh = df[\"vh_protein_sequence\"].astype(str).tolist()\n",
    "        self.vl = df[\"vl_protein_sequence\"].astype(str).tolist()\n",
    "        self.y = df[Y].astype(float).values\n",
    "        if feature_cols:\n",
    "            self.features = df[feature_cols].astype(np.float32).values\n",
    "        else:\n",
    "            self.features = None\n",
    "\n",
    "    # get length\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    # what fed into model\n",
    "    def __getitem__(self, idx):\n",
    "        vh_seq = torch.tensor(one_hot_encode(self.vh[idx]), dtype=torch.float32)\n",
    "        vl_seq = torch.tensor(one_hot_encode(self.vl[idx]), dtype=torch.float32)\n",
    "        target = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "\n",
    "        sample = {\"vh_seq\": vh_seq, \"vl_seq\": vl_seq, \"target\": target}\n",
    "\n",
    "        if self.features is not None:\n",
    "            sample[\"features\"] = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "# can't use built in since sequences are not of the same length, pad with zeros\n",
    "def collate_fn(batch):\n",
    "    vh_seqs = [b[\"vh_seq\"] for b in batch]\n",
    "    vl_seqs = [b[\"vl_seq\"] for b in batch]\n",
    "\n",
    "    batch_out = {\n",
    "        \"vh_seq\": nn.utils.rnn.pad_sequence(vh_seqs, batch_first=True, padding_value=0.0),\n",
    "        \"vl_seq\": nn.utils.rnn.pad_sequence(vl_seqs, batch_first=True, padding_value=0.0),\n",
    "        \"vh_lengths\": torch.tensor([len(s) for s in vh_seqs], dtype=torch.long),\n",
    "        \"vl_lengths\": torch.tensor([len(s) for s in vl_seqs], dtype=torch.long),\n",
    "        \"target\": torch.stack([b[\"target\"] for b in batch]),\n",
    "    }\n",
    "\n",
    "    if \"features\" in batch[0]:\n",
    "        batch_out[\"features\"] = torch.stack([b[\"features\"] for b in batch])\n",
    "\n",
    "    return batch_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "224023c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AntibodyLSTMModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size=20,\n",
    "                 hidden_size=64,\n",
    "                 num_layers=1,\n",
    "                 dropout=0.1,\n",
    "                 engineered_feat_dim=0):\n",
    "        super().__init__()\n",
    "\n",
    "        # one lstm for vh\n",
    "        self.vh_lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers,\n",
    "                               batch_first=True,\n",
    "                               dropout=dropout if num_layers > 1 else 0.0)\n",
    "\n",
    "        # two lstm for vl\n",
    "        self.vl_lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers,\n",
    "                               batch_first=True,\n",
    "                               dropout=dropout if num_layers > 1 else 0.0)\n",
    "\n",
    "        input_dim = hidden_size * 2 + engineered_feat_dim\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, vh_seq, vl_seq, vh_lengths, vl_lengths, features=None):\n",
    "\n",
    "        vh_emb = vh_seq\n",
    "        vl_emb = vl_seq\n",
    "        \n",
    "        # takes padded tensor and lengths, lets LSTM know not to consier PAD tokens\n",
    "        vh_packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            vh_emb, vh_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        vl_packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            vl_emb, vl_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        vh_output, (vh_hidden, vh_cell) = self.vh_lstm(vh_packed)\n",
    "        vl_output, (vl_hidden, vl_cell) = self.vl_lstm(vl_packed)\n",
    "\n",
    "        # extract final layer\n",
    "        vh_repr = vh_hidden[-1]\n",
    "        vl_repr = vl_hidden[-1]\n",
    "\n",
    "        combined = torch.cat([vh_repr, vl_repr], dim=1)  # (B, 2H)\n",
    "\n",
    "        if features is not None:\n",
    "            combined = torch.cat([combined, features], dim=1)  # (B, 2H + Feats)\n",
    "\n",
    "        # mlp scalar prediction\n",
    "        out = self.mlp(combined).squeeze(-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2e4158d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/bmvgr4j50j39w8_bzv8rj7p80000gn/T/ipykernel_1551/4290487054.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[engineered_cols] = train_df[engineered_cols].astype(float)\n",
      "/var/folders/pd/bmvgr4j50j39w8_bzv8rj7p80000gn/T/ipykernel_1551/4290487054.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[engineered_cols] = test_df[engineered_cols].astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 : train ρ: 0.109 | val ρ: 0.338\n",
      "Epoch 02 : train ρ: 0.201 | val ρ: 0.293\n",
      "Epoch 03 : train ρ: 0.227 | val ρ: 0.242\n",
      "Epoch 04 : train ρ: 0.161 | val ρ: 0.241\n",
      "Epoch 05 : train ρ: 0.216 | val ρ: 0.174\n",
      "Epoch 06 : train ρ: 0.167 | val ρ: 0.104\n",
      "Epoch 07 : train ρ: 0.179 | val ρ: 0.076\n",
      "Epoch 08 : train ρ: 0.210 | val ρ: 0.103\n",
      "Epoch 09 : train ρ: 0.270 | val ρ: 0.124\n",
      "Epoch 10 : train ρ: 0.262 | val ρ: 0.149\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/bmvgr4j50j39w8_bzv8rj7p80000gn/T/ipykernel_1551/4290487054.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[engineered_cols] = train_df[engineered_cols].astype(float)\n",
      "/var/folders/pd/bmvgr4j50j39w8_bzv8rj7p80000gn/T/ipykernel_1551/4290487054.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[engineered_cols] = test_df[engineered_cols].astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 : train ρ: 0.161 | val ρ: -0.001\n",
      "Epoch 02 : train ρ: 0.151 | val ρ: -0.082\n",
      "Epoch 03 : train ρ: 0.189 | val ρ: -0.088\n",
      "Epoch 04 : train ρ: 0.243 | val ρ: -0.079\n",
      "Epoch 05 : train ρ: 0.203 | val ρ: -0.074\n",
      "Epoch 06 : train ρ: 0.092 | val ρ: -0.036\n",
      "Epoch 07 : train ρ: 0.152 | val ρ: -0.031\n",
      "Epoch 08 : train ρ: 0.274 | val ρ: -0.038\n",
      "Epoch 09 : train ρ: 0.333 | val ρ: -0.011\n",
      "Epoch 10 : train ρ: 0.337 | val ρ: 0.024\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/bmvgr4j50j39w8_bzv8rj7p80000gn/T/ipykernel_1551/4290487054.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[engineered_cols] = train_df[engineered_cols].astype(float)\n",
      "/var/folders/pd/bmvgr4j50j39w8_bzv8rj7p80000gn/T/ipykernel_1551/4290487054.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[engineered_cols] = test_df[engineered_cols].astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 : train ρ: -0.014 | val ρ: 0.435\n",
      "Epoch 02 : train ρ: 0.259 | val ρ: 0.424\n",
      "Epoch 03 : train ρ: 0.252 | val ρ: 0.451\n",
      "Epoch 04 : train ρ: 0.294 | val ρ: 0.423\n",
      "Epoch 05 : train ρ: 0.135 | val ρ: 0.354\n",
      "Epoch 06 : train ρ: 0.176 | val ρ: 0.352\n",
      "Epoch 07 : train ρ: 0.135 | val ρ: 0.415\n",
      "Epoch 08 : train ρ: 0.294 | val ρ: 0.458\n",
      "Epoch 09 : train ρ: 0.290 | val ρ: 0.466\n",
      "Epoch 10 : train ρ: 0.300 | val ρ: 0.461\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/bmvgr4j50j39w8_bzv8rj7p80000gn/T/ipykernel_1551/4290487054.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[engineered_cols] = train_df[engineered_cols].astype(float)\n",
      "/var/folders/pd/bmvgr4j50j39w8_bzv8rj7p80000gn/T/ipykernel_1551/4290487054.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[engineered_cols] = test_df[engineered_cols].astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 : train ρ: -0.223 | val ρ: 0.121\n",
      "Epoch 02 : train ρ: 0.050 | val ρ: 0.242\n",
      "Epoch 03 : train ρ: 0.071 | val ρ: 0.280\n",
      "Epoch 04 : train ρ: 0.112 | val ρ: 0.227\n",
      "Epoch 05 : train ρ: -0.028 | val ρ: -0.078\n",
      "Epoch 06 : train ρ: -0.051 | val ρ: 0.114\n",
      "Epoch 07 : train ρ: 0.120 | val ρ: 0.248\n",
      "Epoch 08 : train ρ: 0.279 | val ρ: 0.274\n",
      "Epoch 09 : train ρ: 0.292 | val ρ: 0.275\n",
      "Epoch 10 : train ρ: 0.340 | val ρ: 0.280\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/bmvgr4j50j39w8_bzv8rj7p80000gn/T/ipykernel_1551/4290487054.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[engineered_cols] = train_df[engineered_cols].astype(float)\n",
      "/var/folders/pd/bmvgr4j50j39w8_bzv8rj7p80000gn/T/ipykernel_1551/4290487054.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[engineered_cols] = test_df[engineered_cols].astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 : train ρ: 0.092 | val ρ: 0.197\n",
      "Epoch 02 : train ρ: 0.197 | val ρ: 0.226\n",
      "Epoch 03 : train ρ: 0.127 | val ρ: 0.223\n",
      "Epoch 04 : train ρ: 0.116 | val ρ: 0.197\n",
      "Epoch 05 : train ρ: 0.188 | val ρ: -0.067\n",
      "Epoch 06 : train ρ: 0.151 | val ρ: -0.176\n",
      "Epoch 07 : train ρ: 0.047 | val ρ: -0.079\n",
      "Epoch 08 : train ρ: 0.204 | val ρ: 0.036\n",
      "Epoch 09 : train ρ: 0.227 | val ρ: 0.075\n",
      "Epoch 10 : train ρ: 0.247 | val ρ: 0.093\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def run_epoch(loader, train=True):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_targets = [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        vh_seq = batch[\"vh_seq\"].to(device)\n",
    "        vl_seq = batch[\"vl_seq\"].to(device)\n",
    "        vh_lengths = batch[\"vh_lengths\"].to(device)\n",
    "        vl_lengths = batch[\"vl_lengths\"].to(device)\n",
    "        targets = batch[\"target\"].to(device)\n",
    "\n",
    "        feats = batch.get(\"features\")\n",
    "        if feats is not None:\n",
    "            feats = feats.to(device)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            preds = model(vh_seq, vl_seq, vh_lengths, vl_lengths, features=feats)\n",
    "            loss = criterion(preds, targets)\n",
    "\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * targets.size(0)\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "        all_targets.append(targets.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    if np.std(all_preds) < 1e-8 or np.std(all_targets) < 1e-8:\n",
    "        spearman = np.nan\n",
    "    else:\n",
    "        rho, _ = spearmanr(all_targets, all_preds)\n",
    "        spearman = float(rho)\n",
    "\n",
    "    return avg_loss, spearman\n",
    "\n",
    "\n",
    "for test_fold in range(5):\n",
    "    train_df, test_df = df.loc[df['hierarchical_cluster_IgG_isotype_stratified_fold']!=test_fold], df.loc[df['hierarchical_cluster_IgG_isotype_stratified_fold']==test_fold]\n",
    "\n",
    "    train_df[engineered_cols] = train_df[engineered_cols].astype(float)\n",
    "    test_df[engineered_cols] = test_df[engineered_cols].astype(float)\n",
    "\n",
    "    # normalize all the other features\n",
    "    scaler = StandardScaler()\n",
    "    train_df.loc[:, engineered_cols] = scaler.fit_transform(train_df[engineered_cols])\n",
    "    test_df.loc[:, engineered_cols] = scaler.transform(test_df[engineered_cols])\n",
    "\n",
    "    train_dataset = AntibodySeqDataset(train_df, feature_cols=engineered_cols)\n",
    "    test_dataset  = AntibodySeqDataset(test_df,  feature_cols=engineered_cols)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                              shuffle=True,  collate_fn=collate_fn)\n",
    "    test_loader  = DataLoader(test_dataset,  batch_size=batch_size,\n",
    "                              shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    model = AntibodyLSTMModel(engineered_feat_dim=len(engineered_cols)).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss, train_rho = run_epoch(train_loader, train=True)\n",
    "        val_loss, val_rho = run_epoch(test_loader, train=False)\n",
    "        print(\n",
    "            f\"Epoch {epoch:02d} : \"\n",
    "            f\"train ρ: {train_rho:.3f} | \"\n",
    "            f\"val ρ: {val_rho:.3f}\"\n",
    "        )\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598024ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msse-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
